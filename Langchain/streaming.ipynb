{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb32829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected argument 'streaming' provided to ChatGoogleGenerativeAI. Did you mean: 'disable_streaming'?\n",
      "C:\\Users\\Acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3550: UserWarning: WARNING! streaming is not default parameter.\n",
      "                streaming was transferred to model_kwargs.\n",
      "                Please confirm that streaming is what you intended.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "gemini_api =\"AIzaSyDaM0twsGt6Rv5M2pY4ze4lZlKc7IQWuiQ\"\n",
    "\n",
    "# Directly pass API key to avoid ADC errors\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key= gemini_api,\n",
    "    temperature = 0.0,\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0f12d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Vinith! Nice to meet you. I'm an AI assistant.\\n\\nHow can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--fa5f7f73-588c-4634-9bf7-8851d4924c8d-0', usage_metadata={'input_tokens': 5, 'output_tokens': 24, 'total_tokens': 493, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 464}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi im vinith\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353fc2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**NLP stands for Natural Language Processing.**\n",
      "\n",
      "It's a subfield of **artificial intelligence (|AI)** and **computer science** that focuses on enabling computers to understand, interpret, and generate human language in a valuable way.\n",
      "\n",
      "Think of it as teaching computers to \"read,\" \"listen,\" \"understand,\" and \"speak\" like| humans do.\n",
      "\n",
      "### The Core Goal of NLP:\n",
      "\n",
      "The ultimate goal of NLP is to **bridge the communication gap between humans and computers**. It allows computers to process and make sense of the vast amount of text and speech data that humans produce| every day, and to respond in a way that is natural and meaningful to us.\n",
      "\n",
      "### How NLP Works (Simplified):\n",
      "\n",
      "NLP combines computational linguistics (rule-based modeling of human language) with machine learning, deep learning, and statistical methods. It involves|:\n",
      "\n",
      "1.  **Breaking down language:** Analyzing words, phrases, sentences, and paragraphs.\n",
      "2.  **Understanding structure:** Identifying grammar, syntax, and relationships between words.\n",
      "3.  **Interpreting meaning:** Gr|asping the semantics (meaning of words and sentences) and pragmatics (meaning in context).\n",
      "4.  **Generating language:** Creating human-like text or speech.\n",
      "\n",
      "### Key Tasks and Applications of NLP:\n",
      "\n",
      "NLP powers many technologies| we use daily:\n",
      "\n",
      "*   **Speech Recognition:** Converting spoken language into text (e.g., Siri, Alexa, Google Assistant, voice dictation).\n",
      "*   **Machine Translation:** Translating text or speech from one language to another| (e.g., Google Translate).\n",
      "*   **Sentiment Analysis:** Determining the emotional tone or opinion expressed in text (e.g., analyzing customer reviews, social media monitoring).\n",
      "*   **Text Summarization:** Condensing long documents| into shorter, coherent summaries.\n",
      "*   **Named Entity Recognition (NER):** Identifying and classifying key information in text, such as names of people, organizations, locations, dates, etc.\n",
      "*   **Question Answering:** Enabling| systems to answer questions posed in natural language (e.g., chatbots, search engines).\n",
      "*   **Chatbots and Virtual Assistants:** Powering conversational AI for customer service, information retrieval, and more.\n",
      "*   **Spam Detection:** Identifying| and filtering unwanted emails.\n",
      "*   **Spell and Grammar Checking:** Tools that correct writing errors.\n",
      "*   **Information Extraction:** Pulling specific data points from unstructured text.\n",
      "\n",
      "### Challenges in NLP:\n",
      "\n",
      "Human language is incredibly complex and| nuanced, making NLP a challenging field:\n",
      "\n",
      "*   **Ambiguity:** Words can have multiple meanings (e.g., \"bank\" â€“ river bank vs. financial institution).\n",
      "*   **Context:** The meaning of words and sentences often| depends heavily on the surrounding text.\n",
      "*   **Sarcasm and Irony:** These are very difficult for computers to detect.\n",
      "*   **Slang and New Words:** Language is constantly evolving.\n",
      "*   **Grammatical Errors and| Typos:** Real-world text often contains imperfections.\n",
      "*   **Cultural Nuances:** Different cultures express things differently.\n",
      "\n",
      "In essence, NLP is about teaching computers to \"think\" about language in a way that mimics human understanding, opening up a| world of possibilities for automation, information access, and intelligent interaction.|"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "async for token in llm.astream(\"What is NLP?\"):\n",
    "    tokens.append(token)\n",
    "    print(token.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6179003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessageChunk(content=\"**NLP stands for Natural Language Processing.**\\n\\nIt's a subfield of **artificial intelligence (\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 5, 'output_tokens': 20, 'total_tokens': 1156, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content='AI)** and **computer science** that focuses on enabling computers to understand, interpret, and generate human language in a valuable way.\\n\\nThink of it as teaching computers to \"read,\" \"listen,\" \"understand,\" and \"speak\" like', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 48, 'total_tokens': 48, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' humans do.\\n\\n### The Core Goal of NLP:\\n\\nThe ultimate goal of NLP is to **bridge the communication gap between humans and computers**. It allows computers to process and make sense of the vast amount of text and speech data that humans produce', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 49, 'total_tokens': 49, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' every day, and to respond in a way that is natural and meaningful to us.\\n\\n### How NLP Works (Simplified):\\n\\nNLP combines computational linguistics (rule-based modeling of human language) with machine learning, deep learning, and statistical methods. It involves', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 52, 'total_tokens': 52, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=':\\n\\n1.  **Breaking down language:** Analyzing words, phrases, sentences, and paragraphs.\\n2.  **Understanding structure:** Identifying grammar, syntax, and relationships between words.\\n3.  **Interpreting meaning:** Gr', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 49, 'total_tokens': 49, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content='asping the semantics (meaning of words and sentences) and pragmatics (meaning in context).\\n4.  **Generating language:** Creating human-like text or speech.\\n\\n### Key Tasks and Applications of NLP:\\n\\nNLP powers many technologies', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 49, 'total_tokens': 49, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' we use daily:\\n\\n*   **Speech Recognition:** Converting spoken language into text (e.g., Siri, Alexa, Google Assistant, voice dictation).\\n*   **Machine Translation:** Translating text or speech from one language to another', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 49, 'total_tokens': 49, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' (e.g., Google Translate).\\n*   **Sentiment Analysis:** Determining the emotional tone or opinion expressed in text (e.g., analyzing customer reviews, social media monitoring).\\n*   **Text Summarization:** Condensing long documents', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 49, 'total_tokens': 49, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' into shorter, coherent summaries.\\n*   **Named Entity Recognition (NER):** Identifying and classifying key information in text, such as names of people, organizations, locations, dates, etc.\\n*   **Question Answering:** Enabling', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 48, 'total_tokens': 48, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' systems to answer questions posed in natural language (e.g., chatbots, search engines).\\n*   **Chatbots and Virtual Assistants:** Powering conversational AI for customer service, information retrieval, and more.\\n*   **Spam Detection:** Identifying', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 51, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' and filtering unwanted emails.\\n*   **Spell and Grammar Checking:** Tools that correct writing errors.\\n*   **Information Extraction:** Pulling specific data points from unstructured text.\\n\\n### Challenges in NLP:\\n\\nHuman language is incredibly complex and', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 49, 'total_tokens': 49, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' nuanced, making NLP a challenging field:\\n\\n*   **Ambiguity:** Words can have multiple meanings (e.g., \"bank\" â€“ river bank vs. financial institution).\\n*   **Context:** The meaning of words and sentences often', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 50, 'total_tokens': 50, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' depends heavily on the surrounding text.\\n*   **Sarcasm and Irony:** These are very difficult for computers to detect.\\n*   **Slang and New Words:** Language is constantly evolving.\\n*   **Grammatical Errors and', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 50, 'total_tokens': 50, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' Typos:** Real-world text often contains imperfections.\\n*   **Cultural Nuances:** Different cultures express things differently.\\n\\nIn essence, NLP is about teaching computers to \"think\" about language in a way that mimics human understanding, opening up a', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 51, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}}),\n",
       " AIMessageChunk(content=' world of possibilities for automation, information access, and intelligent interaction.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--38e925c7-6a1f-46bb-843e-5ec8cb54bb1b', usage_metadata={'input_tokens': 0, 'output_tokens': 13, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1131}})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8075ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58befb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x\n",
    "\n",
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`. You MUST use this tool\n",
    "    to conclude the interaction.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1dcbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, multiply, exponentiate, subtract, final_answer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cdf854d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x00000279956B3AF0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db44ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided back to you. You MUST \"\n",
    "        \"then use the final_answer tool to provide a final answer to the user. \"\n",
    "        \"DO NOT use the same tool more than once.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10761363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate, final_answer]\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cbae6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "class CustomAgentExecutor:\n",
    "    chat_history: list[BaseMessage]\n",
    "\n",
    "    def __init__(self, max_iterations: int = 3):\n",
    "        self.chat_history = []\n",
    "        self.max_iterations = max_iterations\n",
    "        self.agent: RunnableSerializable = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "            }\n",
    "            | prompt\n",
    "            | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    "        )\n",
    "\n",
    "\n",
    "    def invoke(self, input: str) -> dict:\n",
    "        # invoke the agent but we do this iteratively in a loop until\n",
    "        # reaching a final answer\n",
    "        count = 0\n",
    "        agent_scratchpad = []\n",
    "        while count < self.max_iterations:\n",
    "            # invoke a step for the agent to generate a tool call\n",
    "            tool_call = self.agent.invoke({\n",
    "                \"input\": input,\n",
    "                \"chat_history\": self.chat_history,\n",
    "                \"agent_scratchpad\": agent_scratchpad\n",
    "            })\n",
    "            # add initial tool call to scratchpad\n",
    "            agent_scratchpad.append(tool_call)\n",
    "            # otherwise we execute the tool and add it's output to the agent scratchpad\n",
    "            tool_name = tool_call.tool_calls[0][\"name\"]\n",
    "            tool_args = tool_call.tool_calls[0][\"args\"]\n",
    "            tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    "            tool_out = name2tool[tool_name](**tool_args)\n",
    "            # add the tool output to the agent scratchpad\n",
    "            tool_exec = ToolMessage(\n",
    "                content=f\"{tool_out}\",\n",
    "                tool_call_id=tool_call_id\n",
    "            )\n",
    "            agent_scratchpad.append(tool_exec)\n",
    "            # add a print so we can see intermediate steps\n",
    "            print(f\"{count}: {tool_name}({tool_args})\")\n",
    "            count += 1\n",
    "            # if the tool call is the final answer tool, we stop\n",
    "            if tool_name == \"final_answer\":\n",
    "                break\n",
    "        # add the final output to the chat history\n",
    "        final_answer = tool_out[\"answer\"]\n",
    "        self.chat_history.extend([\n",
    "            HumanMessage(content=input),\n",
    "            AIMessage(content=final_answer)\n",
    "        ])\n",
    "        # return the final answer in dict form\n",
    "        return json.dumps(tool_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b469e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
