{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c871f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the user's query based on the context below.\n",
    "If you cannot answer the question using the\n",
    "provided information answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065a5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f665a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03a07e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.\\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nContext: {context}\\n'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156f8a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:502: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "gemini_api =\"AIzaSyDaM0twsGt6Rv5M2pY4ze4lZlKc7IQWuiQ\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key= gemini_api,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cb38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    {\n",
    "        \"context\": lambda x: x[\"context\"],\n",
    "        \"query\": lambda x: x[\"query\"]\n",
    "    }\n",
    "    | prompt_template\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa094a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Aurelio AI is an AI company developing tooling for AI\n",
    "engineers. Their focus is on language AI with the team having strong\n",
    "expertise in building AI agents and a strong background in\n",
    "information retrieval.\n",
    "\n",
    "The company is behind several open source frameworks, most notably\n",
    "Semantic Router and Semantic Chunkers. They also have an AI\n",
    "Platform providing engineers with tooling to help them build with\n",
    "AI. Finally, the team also provides development services to other\n",
    "organizations to help them bring their AI tech to market.\n",
    "\n",
    "Aurelio AI became LangChain Experts in September 2024 after a long\n",
    "track record of delivering AI solutions built with the LangChain\n",
    "ecosystem.\"\"\"\n",
    "\n",
    "query = \"what does Aurelio AI do?\"\n",
    "# query = \"who is vinith?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a7eb3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't know.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--f4942a88-8926-4582-9f9d-bda0d20734f8-0', usage_metadata={'input_tokens': 208, 'output_tokens': 6, 'total_tokens': 355, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 141}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.invoke({\"query\": query, \"context\": context})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed3e57",
   "metadata": {},
   "source": [
    "##Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b403dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dde34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"Here is query #1\", \"output\": \"Here is the answer #1\"},\n",
    "    {\"input\": \"Here is query #2\", \"output\": \"Here is the answer #2\"},\n",
    "    {\"input\": \"Here is query #3\", \"output\": \"Here is the answer #3\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cab755d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Here is query #1\n",
      "AI: Here is the answer #1\n",
      "Human: Here is query #2\n",
      "AI: Here is the answer #2\n",
      "Human: Here is query #3\n",
      "AI: Here is the answer #3\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "# here is the formatted prompt\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37ab37c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "new_system_prompt = \"\"\"\n",
    "Answer the user's query based on the context below.\n",
    "If you cannot answer the question using the\n",
    "provided information answer with \"I don't know\".\n",
    "\n",
    "Always answer in markdown format. When doing so please\n",
    "provide headers, short summaries, follow with bullet\n",
    "points, then conclude.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template.messages[0].prompt.template = new_system_prompt\n",
    "\n",
    "out = pipeline.invoke({\"query\": query, \"context\": context}).content\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb06c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Can you explain gravity?\",\n",
    "        \"output\": (\n",
    "            \"## Gravity\\n\\n\"\n",
    "            \"Gravity is one of the fundamental forces in the universe.\\n\\n\"\n",
    "            \"### Discovery\\n\\n\"\n",
    "            \"* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\\n\"\n",
    "            \"* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\\n\\n\"\n",
    "            \"### In General Relativity\\n\\n\"\n",
    "            \"* Gravity is described as the curvature of spacetime.\\n\"\n",
    "            \"* The more massive an object is, the more it curves spacetime.\\n\"\n",
    "            \"* This curvature is what causes objects to fall towards each other.\\n\\n\"\n",
    "            \"### Gravitons\\n\\n\"\n",
    "            \"* Gravitons are hypothetical particles that mediate the force of gravity.\\n\"\n",
    "            \"* They have not yet been detected.\\n\\n\"\n",
    "            \"**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\\n\\n\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the capital of France?\",\n",
    "        \"output\": (\n",
    "            \"## France\\n\\n\"\n",
    "            \"The capital of France is Paris.\\n\\n\"\n",
    "            \"### Origins\\n\\n\"\n",
    "            \"* The name Paris comes from the Latin word \\\"Parisini\\\" which referred to a Celtic people living in the area.\\n\"\n",
    "            \"* The Romans named the city Lutetia, which means \\\"the place where the river turns\\\".\\n\"\n",
    "            \"* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\\n\\n\"\n",
    "            \"**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\\n\\n\"\n",
    "        )\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bb84609",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "214344da",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = few_shot_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1953ef14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Human: Can you explain gravity?\n",
       "AI: ## Gravity\n",
       "\n",
       "Gravity is one of the fundamental forces in the universe.\n",
       "\n",
       "### Discovery\n",
       "\n",
       "* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\n",
       "* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\n",
       "\n",
       "### In General Relativity\n",
       "\n",
       "* Gravity is described as the curvature of spacetime.\n",
       "* The more massive an object is, the more it curves spacetime.\n",
       "* This curvature is what causes objects to fall towards each other.\n",
       "\n",
       "### Gravitons\n",
       "\n",
       "* Gravitons are hypothetical particles that mediate the force of gravity.\n",
       "* They have not yet been detected.\n",
       "\n",
       "**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\n",
       "\n",
       "\n",
       "Human: What is the capital of France?\n",
       "AI: ## France\n",
       "\n",
       "The capital of France is Paris.\n",
       "\n",
       "### Origins\n",
       "\n",
       "* The name Paris comes from the Latin word \"Parisini\" which referred to a Celtic people living in the area.\n",
       "* The Romans named the city Lutetia, which means \"the place where the river turns\".\n",
       "* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\n",
       "\n",
       "**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f3aee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cot_system_prompt = \"\"\"\n",
    "Be a helpful assistant and answer the user's question.\n",
    "\n",
    "You MUST answer the question directly without any other\n",
    "text or explanation.\n",
    "\"\"\"\n",
    "\n",
    "no_cot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", no_cot_system_prompt),\n",
    "    (\"user\", \"{query}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d00b915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"How many keystrokes are needed to type the numbers from 1 to 500?\"\n",
    ")\n",
    "\n",
    "\n",
    "no_cot_pipeline = no_cot_prompt_template | llm\n",
    "no_cot_result = no_cot_pipeline.invoke({\"query\": query})\n",
    "print(no_cot_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b05814b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_system_prompt = \"\"\"\n",
    "Be a helpful assistant and answer the user's question.\n",
    "\n",
    "To answer the question, you must:\n",
    "\n",
    "- List systematically and in precise detail all\n",
    "  subproblems that need to be solved to answer the\n",
    "  question.\n",
    "- Solve each sub problem INDIVIDUALLY and in sequence.\n",
    "- Finally, use everything you have worked through to\n",
    "  provide the final answer.\n",
    "\"\"\"\n",
    "\n",
    "cot_system_prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", cot_system_prompt),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea894864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine the total number of keystrokes needed to type the numbers from 1 to 500, we need to break down the problem based on the number of digits each number has.\n",
       "\n",
       "### Subproblems:\n",
       "\n",
       "1.  **Calculate keystrokes for single-digit numbers:** (1 to 9)\n",
       "2.  **Calculate keystrokes for two-digit numbers:** (10 to 99)\n",
       "3.  **Calculate keystrokes for three-digit numbers:** (100 to 500)\n",
       "4.  **Sum the keystrokes** from all categories.\n",
       "\n",
       "### Solving Each Subproblem Individually:\n",
       "\n",
       "#### Subproblem 1: Keystrokes for single-digit numbers (1 to 9)\n",
       "\n",
       "*   **Numbers in this range:** 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
       "*   **Count of numbers:** There are 9 numbers.\n",
       "*   **Keystrokes per number:** Each number requires 1 keystroke.\n",
       "*   **Total keystrokes for this range:** 9 numbers * 1 keystroke/number = 9 keystrokes.\n",
       "\n",
       "#### Subproblem 2: Keystrokes for two-digit numbers (10 to 99)\n",
       "\n",
       "*   **Numbers in this range:** 10, 11, ..., 99\n",
       "*   **Count of numbers:** 99 - 10 + 1 = 90 numbers.\n",
       "*   **Keystrokes per number:** Each number requires 2 keystrokes.\n",
       "*   **Total keystrokes for this range:** 90 numbers * 2 keystrokes/number = 180 keystrokes.\n",
       "\n",
       "#### Subproblem 3: Keystrokes for three-digit numbers (100 to 500)\n",
       "\n",
       "*   **Numbers in this range:** 100, 101, ..., 500\n",
       "*   **Count of numbers:** 500 - 100 + 1 = 401 numbers.\n",
       "*   **Keystrokes per number:** Each number requires 3 keystrokes.\n",
       "*   **Total keystrokes for this range:** 401 numbers * 3 keystrokes/number = 1203 keystrokes.\n",
       "\n",
       "### Final Answer:\n",
       "\n",
       "To find the total number of keystrokes, we sum the keystrokes from all the subproblems:\n",
       "\n",
       "Total Keystrokes = (Keystrokes for 1-digit numbers) + (Keystrokes for 2-digit numbers) + (Keystrokes for 3-digit numbers)\n",
       "Total Keystrokes = 9 + 180 + 1203\n",
       "Total Keystrokes = 1392\n",
       "\n",
       "Therefore, 1392 keystrokes are needed to type the numbers from 1 to 500."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cot_system_pipeline = cot_system_prompt_template | llm\n",
    "cot_system_result = cot_system_pipeline.invoke({\"query\": query})\n",
    "display(Markdown(cot_system_result.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da233ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Be a helpful assistant and answer the user's question.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{query}\"),\n",
    "])\n",
    "\n",
    "pipeline = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b51b04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break this down by the number of digits required for each number:\n",
       "\n",
       "1.  **1-digit numbers (1 to 9):**\n",
       "    *   There are 9 numbers (1, 2, 3, 4, 5, 6, 7, 8, 9).\n",
       "    *   Each requires 1 keystroke.\n",
       "    *   Total keystrokes: 9 * 1 = 9\n",
       "\n",
       "2.  **2-digit numbers (10 to 99):**\n",
       "    *   There are 90 numbers (99 - 10 + 1 = 90).\n",
       "    *   Each requires 2 keystrokes.\n",
       "    *   Total keystrokes: 90 * 2 = 180\n",
       "\n",
       "3.  **3-digit numbers (100 to 500):**\n",
       "    *   There are 401 numbers (500 - 100 + 1 = 401).\n",
       "    *   Each requires 3 keystrokes.\n",
       "    *   Total keystrokes: 401 * 3 = 1203\n",
       "\n",
       "**Total Keystrokes:**\n",
       "Add the keystrokes from each category:\n",
       "9 (1-digit) + 180 (2-digit) + 1203 (3-digit) = **1392 keystrokes**\n",
       "\n",
       "Therefore, 1392 keystrokes are needed to type the numbers from 1 to 500."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pipeline.invoke({\"query\": query}).content\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961de8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
