{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bdb389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586605ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
    "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51823f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7064b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493ba3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:502: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "gemini_api =\"AIzaSyDaM0twsGt6Rv5M2pY4ze4lZlKc7IQWuiQ\"\n",
    "\n",
    "# Directly pass API key to avoid ADC errors\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key= gemini_api,\n",
    "    temperature = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624643b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e27e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_23304\\1153200289.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key= \"chat_history\",\n",
    "    return_messages= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0d673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm, tools=tools, prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2c9f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolAgentAction(tool='multiply', tool_input={'y': 7.68, 'x': 10.7}, log=\"\\nInvoking: `multiply` with `{'y': 7.68, 'x': 10.7}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"y\": 7.68, \"x\": 10.7}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--25c76563-acd9-434d-94b6-9f1b7d948b4a-0', tool_calls=[{'name': 'multiply', 'args': {'y': 7.68, 'x': 10.7}, 'id': 'ed5ae295-7819-4c64-ab89-6a3862686814', 'type': 'tool_call'}], usage_metadata={'input_tokens': 222, 'output_tokens': 24, 'total_tokens': 337, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 91}})], tool_call_id='ed5ae295-7819-4c64-ab89-6a3862686814')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\n",
    "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "    \"intermediate_steps\": []  # agent will append it's internal steps here\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280d271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "055009ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'y': 7.68, 'x': 10.7}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m82.17599999999999\u001b[0m\u001b[32;1m\u001b[1;3m10.7 multiplied by 7.68 is 82.176.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 10.7 multiplied by 7.68?',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '10.7 multiplied by 7.68 is 82.176.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71b7389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello James, how can I help you?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My name is James',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello James, how can I help you?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Hello James, how can I help you?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"My name is James\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb7d695d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'y': 10.0, 'x': 9.0}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m19.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'y': 2.0, 'x': 4.0}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m8.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `subtract` with `{'y': 19.0, 'x': 8.0}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m11.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'y': 3.0, 'x': 11.0}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1331.0\u001b[0m\u001b[32;1m\u001b[1;3mThe answer is 1331.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is nine plus 10, minus 4 * 2, to the power of 3',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello James, how can I help you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The answer is 1331.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The answer is 1331.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is nine plus 10, minus 4 * 2, to the power of 3\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fba4523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI do not know your name. I am a large language model, able to communicate in response to a wide range of prompts and questions, but I have no memory of past conversations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello James, how can I help you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The answer is 1331.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I do not know your name. I am a large language model, able to communicate in response to a wide range of prompts and questions, but I have no memory of past conversations.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'I do not know your name. I am a large language model, able to communicate in response to a wide range of prompts and questions, but I have no memory of past conversations.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is my name\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf81401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2869fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"14ac1ec6347d01ae4929d4bd869667ca444690946cb21a18d9abe23172a2cfae\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "211b9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "toolbox = load_tools(tool_names=['serpapi'], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1df40b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def get_location_from_ip():\n",
    "    \"\"\"Get the geographical location based on the IP address.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"https://ipinfo.io/json\")\n",
    "        data = response.json()\n",
    "        if 'loc' in data:\n",
    "            latitude, longitude = data['loc'].split(',')\n",
    "            data = (\n",
    "                f\"Latitude: {latitude},\\n\"\n",
    "                f\"Longitude: {longitude},\\n\"\n",
    "                f\"City: {data.get('city', 'N/A')},\\n\"\n",
    "                f\"Country: {data.get('country', 'N/A')}\"\n",
    "            )\n",
    "            return data\n",
    "        else:\n",
    "            return \"Location could not be determined.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error occurred: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"Return the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06a8f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "074b7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = toolbox + [get_current_datetime, get_location_from_ip]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm, tools=tools, prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8220b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_datetime` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m2025-06-26 08:07:17\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_location_from_ip` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLatitude: 16.2425,\n",
      "Longitude: 80.6398,\n",
      "City: Thenali,\n",
      "Country: IN\u001b[0m\u001b[32;1m\u001b[1;3mIt is 08:07:17 on 2025-06-26. I'm sorry, I cannot tell you the weather in your current location. My tools do not have the ability to check the weather.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "out = agent_executor.invoke({\n",
    "    \"input\": (\n",
    "        \"I have a few questions, what is the date and time right now? \"\n",
    "        \"How is the weather where I am? Please give me degrees in Celsius\"\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
